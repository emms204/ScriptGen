{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db10bcac-76df-4e59-b85d-94bc124d9b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TTS.utils.manage.ModelManager object at 0x7f81130a4d10>\n",
      " > tts_models/multilingual/multi-dataset/xtts_v2 is already downloaded.\n",
      " > Using model: xtts\n",
      " > Text splitted to sentences.\n",
      "['This forest... it‚Äôs more confusing than the maps suggested.']\n",
      " > Processing time: 3.5181386470794678\n",
      " > Real-time factor: 0.7265749772225972\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/workspace/face_anim_project/male_test_happy_2min.wav'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from TTS.api import TTS\n",
    "\n",
    "# Get device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# List available üê∏TTS models\n",
    "print(TTS().list_models())\n",
    "\n",
    "# Init TTS\n",
    "tts = TTS(\"tts_models/multilingual/multi-dataset/xtts_v2\").to(device)\n",
    "\n",
    "# Run TTS\n",
    "# ‚ùó Since this model is multi-lingual voice cloning model, we must set the target speaker_wav and language\n",
    "# Text to speech list of amplitude values as output\n",
    "# wav = tts.tts(text=\"Hello world!\", speaker_wav=\"/workspace/face_anim_project/ref_audio/male_ref_2_16.wav\", language=\"en\")\n",
    "# Text to speech to a file\n",
    "tts.tts_to_file(text=\"<happy> This forest... it‚Äôs more confusing than the maps suggested.\", speaker_wav=\"/workspace/face_anim_project/ref_audio/male_ref_2_min.wav\", language=\"en\", file_path=\"/workspace/face_anim_project/male_test_happy_2min.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed774ee4-a7cf-4429-867a-f4abf1b93121",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_male_lines = [\"This forest... it‚Äôs more confusing than the maps suggested.\", \"Yes, charming indeed. If only charm could guide us back on course.\",\n",
    "                      \"\",\"\",\n",
    "                     \"\",\"\",\n",
    "                     \"\",\"\",\n",
    "                     \"\",\"\"]\n",
    "list_of_female_lines = [\"Aye, but that‚Äôs part of its charm, isn‚Äôt it? Look at the way the light dances through the leaves.\", \"We mustn‚Äôt let ourselves get lost in wonder when we have a task at hand. We need to find the sacred artifact.\",\n",
    "                       \"\",\"\",\n",
    "                     \"\",\"\",\n",
    "                     \"\",\"\",\n",
    "                     \"\",\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf941b5c-76fc-4187-821e-8dfd1c602911",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_with_lines = {'SIR CEDRIC  ': {1: 'This forest... it‚Äôs more confusing than the maps suggested.',\n",
    "                                    3: 'Yes, charming indeed. If only charm could guide us back on course.',\n",
    "                                    5: 'Right. A task. It‚Äôs just... what if I‚Äôm not the knight they think I am? What if I can‚Äôt lead us out of here?',\n",
    "                                    7: 'It‚Äôs not just a forest! It‚Äôs enchanted, filled with ancient magic. I feel like a fool wandering blindly while you‚Äî',\n",
    "                                    9: 'Together... yes. But how can we trust each other if we can‚Äôt even trust ourselves?',\n",
    "                                    11: \"You did what you thought was right. We all face our failures‚Äîit's part of being human.\",\n",
    "                                    13: 'Alright then, one foot at a time it is. Which way do you think we should go?',\n",
    "                                    15: 'Lead on, Lady Elara. Let us see where this path takes us.'},\n",
    "                   'LADY ELARA  ': {2: 'Aye, but that‚Äôs part of its charm, isn‚Äôt it? Look at the way the light dances through the leaves.',\n",
    "                                    4: 'We mustn‚Äôt let ourselves get lost in wonder when we have a task at hand. We need to find the sacred artifact.',\n",
    "                                    6: 'Sir Cedric, you‚Äôve faced dragons and armies. You‚Äôve fought for honor. Do you really doubt yourself in a mere forest?',\n",
    "                                    8: \"While I what? Have the forest's secrets whispered in my ear? Cedric, this place is unpredictable for everyone. We‚Äôre in this together.\",\n",
    "                                    10: 'You‚Äôre not alone in this. I carry my own burdens as well. Remember when I failed my last quest? I felt like a shadow of my former self.',\n",
    "                                    12: 'Exactly. And it‚Äôs how we rise from those failures that truly defines us. Let‚Äôs take each step together, one foot at a time.',\n",
    "                                    14: 'Let‚Äôs follow the sound of the water. Water often leads to life‚Äîand perhaps to our artifact.'}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59282726-a4fa-44c5-b131-99bfbfd3f085",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(dict_of_replics, output_folder):\n",
    "        dict_with_audio = {}\n",
    "        for key, value in dict_of_replics.items():\n",
    "            #get the ref source audio path by the name\n",
    "            print(key)\n",
    "            for ind, line in value.items():\n",
    "                # dict_with_audio[key][ind] = self.generate(path_to_ref_audio = ref_audio, \n",
    "                #                                           source_transcript = ref_transcript,\n",
    "                #                                           output_transcript = line)\n",
    "                key_to_write = key.replace(' ', '_')\n",
    "                key_to_write = key_to_write.replace('__','')\n",
    "                # print(key_to_write)\n",
    "                if key == 'SIR CEDRIC  ':\n",
    "                    tts.tts_to_file(text=line,\n",
    "                                speaker_wav=\"/workspace/face_anim_project/ref_audio/male_ref_2_min.wav\",\n",
    "                                language=\"en\", file_path=f\"/workspace/face_anim_project/CTTS_TEST/{key_to_write}_{ind}.wav\")\n",
    "                elif key == 'LADY ELARA  ':\n",
    "                    tts.tts_to_file(text=line,\n",
    "                                speaker_wav=\"/workspace/face_anim_project/ref_audio/gg_2_min.wav\",\n",
    "                                language=\"en\", file_path=f\"/workspace/face_anim_project/CTTS_TEST/{key_to_write}_{ind}.wav\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "42d86c75-4831-4374-b1bb-d6d384552bc3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIR CEDRIC  \n",
      " > Text splitted to sentences.\n",
      "['This forest... it‚Äôs more confusing than the maps suggested.']\n",
      " > Processing time: 3.7939319610595703\n",
      " > Real-time factor: 0.7293224276517255\n",
      " > Text splitted to sentences.\n",
      "['Yes, charming indeed.', 'If only charm could guide us back on course.']\n",
      " > Processing time: 4.741457939147949\n",
      " > Real-time factor: 0.7343584763304414\n",
      " > Text splitted to sentences.\n",
      "['Right.', 'A task.', 'It‚Äôs just... what if I‚Äôm not the knight they think I am?', 'What if I can‚Äôt lead us out of here?']\n",
      " > Processing time: 8.669091701507568\n",
      " > Real-time factor: 0.7816731222939097\n",
      " > Text splitted to sentences.\n",
      "['It‚Äôs not just a forest!', 'It‚Äôs enchanted, filled with ancient magic.', 'I feel like a fool wandering blindly while you‚Äî']\n",
      " > Processing time: 8.671023845672607\n",
      " > Real-time factor: 0.7573201557334155\n",
      " > Text splitted to sentences.\n",
      "['Together... yes.', 'But how can we trust each other if we can‚Äôt even trust ourselves?']\n",
      " > Processing time: 5.512273073196411\n",
      " > Real-time factor: 0.853742563384896\n",
      " > Text splitted to sentences.\n",
      "['You did what you thought was right.', \"We all face our failures‚Äîit's part of being human.\"]\n",
      " > Processing time: 6.347119569778442\n",
      " > Real-time factor: 0.9327281037642265\n",
      " > Text splitted to sentences.\n",
      "['Alright then, one foot at a time it is.', 'Which way do you think we should go?']\n",
      " > Processing time: 5.456141948699951\n",
      " > Real-time factor: 0.86527567584029\n",
      " > Text splitted to sentences.\n",
      "['Lead on, Lady Elara.', 'Let us see where this path takes us.']\n",
      " > Processing time: 4.304326295852661\n",
      " > Real-time factor: 0.7836062980808387\n",
      "LADY ELARA  \n",
      " > Text splitted to sentences.\n",
      "['Aye, but that‚Äôs part of its charm, isn‚Äôt it?', 'Look at the way the light dances through the leaves.']\n",
      " > Processing time: 5.59935998916626\n",
      " > Real-time factor: 0.7546076652718318\n",
      " > Text splitted to sentences.\n",
      "['We mustn‚Äôt let ourselves get lost in wonder when we have a task at hand.', 'We need to find the sacred artifact.']\n",
      " > Processing time: 5.05988883972168\n",
      " > Real-time factor: 0.7166659103023063\n",
      " > Text splitted to sentences.\n",
      "['Sir Cedric, you‚Äôve faced dragons and armies.', 'You‚Äôve fought for honor.', 'Do you really doubt yourself in a mere forest?']\n",
      " > Processing time: 5.963078260421753\n",
      " > Real-time factor: 0.7779861050500547\n",
      " > Text splitted to sentences.\n",
      "['While I what?', \"Have the forest's secrets whispered in my ear?\", 'Cedric, this place is unpredictable for everyone.', 'We‚Äôre in this together.']\n",
      " > Processing time: 8.87631607055664\n",
      " > Real-time factor: 0.730745106615046\n",
      " > Text splitted to sentences.\n",
      "['You‚Äôre not alone in this.', 'I carry my own burdens as well.', 'Remember when I failed my last quest?', 'I felt like a shadow of my former self.']\n",
      " > Processing time: 8.163016557693481\n",
      " > Real-time factor: 0.7501771934896859\n",
      " > Text splitted to sentences.\n",
      "['Exactly.', 'And it‚Äôs how we rise from those failures that truly defines us.', 'Let‚Äôs take each step together, one foot at a time.']\n",
      " > Processing time: 8.433619737625122\n",
      " > Real-time factor: 0.739585249819575\n",
      " > Text splitted to sentences.\n",
      "['Let‚Äôs follow the sound of the water.', 'Water often leads to life‚Äîand perhaps to our artifact.']\n",
      " > Processing time: 4.9377052783966064\n",
      " > Real-time factor: 0.735651360734089\n"
     ]
    }
   ],
   "source": [
    "inference(dict_with_lines, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50a5f6e8-7ce0-42aa-8775-84d0a821baf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from parler_tts import ParlerTTSForConditionalGeneration\n",
    "from transformers import AutoTokenizer\n",
    "import soundfile as sf\n",
    "import os\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "def single_inference_parler(model, tokenizer, prompt, description, output_folder_path, output_file_name):\n",
    "    # if model_size == 'mini':\n",
    "    #     model = ParlerTTSForConditionalGeneration.from_pretrained(\"parler-tts/parler-tts-mini-v1\").to(device)\n",
    "    #     tokenizer = AutoTokenizer.from_pretrained(\"parler-tts/parler-tts-mini-v1\")\n",
    "    # elif model_size=='large':\n",
    "    #     model = ParlerTTSForConditionalGeneration.from_pretrained(\"parler-tts/parler-tts-large-v1\").to(device)\n",
    "    #     tokenizer = AutoTokenizer.from_pretrained(\"parler-tts/parler-tts-large-v1\")\n",
    "\n",
    "    input_ids = tokenizer(description, return_tensors=\"pt\").input_ids.to(device)\n",
    "    prompt_input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)\n",
    "\n",
    "    generation = model.generate(input_ids=input_ids, prompt_input_ids=prompt_input_ids)\n",
    "    audio_arr = generation.cpu().numpy().squeeze()\n",
    "    sf.write(os.path.join(output_folder_path, output_file_name), audio_arr, model.config.sampling_rate)\n",
    "\n",
    "def general_inference(dict_of_replics, output_folder_path = '/workspace/face_anim_project/parler_tts_test_2/'):\n",
    "    model = ParlerTTSForConditionalGeneration.from_pretrained(\"parler-tts/parler-tts-large-v1\").to(device)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"parler-tts/parler-tts-large-v1\")\n",
    "\n",
    "    dict_with_audio = {}\n",
    "    for key, value in dict_of_replics.items():\n",
    "        print(key)\n",
    "        for ind, line in value.items():\n",
    "            key_to_write = key.replace(' ', '_')\n",
    "            key_to_write = key_to_write.replace('__','')\n",
    "            \n",
    "            model_size = 'large'\n",
    "            prompt = line\n",
    "            # print(key_to_write)\n",
    "            if key == 'SIR CEDRIC  ':\n",
    "                output_file_name = f'Jon_{key_to_write}_{ind}.wav'\n",
    "                description = 'Jon speaks slightly animatedly and slightly slowly in delivery, with a very close recording that has no background noise.'\n",
    "                single_inference_parler(model, tokenizer, prompt, description, output_folder_path, output_file_name)\n",
    "                \n",
    "            elif key == 'LADY ELARA  ':\n",
    "                output_file_name = f'Lea_{key_to_write}_{ind}.wav'\n",
    "                description = 'Lea speaks slightly animatedly and slightly slowly in delivery, with a very close recording that has no background noise.'\n",
    "                single_inference_parler(model, tokenizer, prompt, description, output_folder_path, output_file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21f1937c-104f-4576-a7eb-3c94d46aa8f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIR CEDRIC  \n",
      "LADY ELARA  \n"
     ]
    }
   ],
   "source": [
    "general_inference(dict_with_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b30dd0d-0183-4276-adce-d0319480232f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cd5e5f-f7bc-47d2-911b-d9d1db7a771c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
